{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 16, (256, 128, 64), 0.0001), (1, 16, (256, 128, 64), 0.0005), (1, 16, (128, 64, 32), 0.0001), (1, 16, (128, 64, 32), 0.0005), (1, 16, (64, 32, 16), 0.0001), (1, 16, (64, 32, 16), 0.0005), (1, 32, (256, 128, 64), 0.0001), (1, 32, (256, 128, 64), 0.0005), (1, 32, (128, 64, 32), 0.0001), (1, 32, (128, 64, 32), 0.0005), (1, 32, (64, 32, 16), 0.0001), (1, 32, (64, 32, 16), 0.0005), (1, 64, (256, 128, 64), 0.0001), (1, 64, (256, 128, 64), 0.0005), (1, 64, (128, 64, 32), 0.0001), (1, 64, (128, 64, 32), 0.0005), (1, 64, (64, 32, 16), 0.0001), (1, 64, (64, 32, 16), 0.0005), (4, 16, (256, 128, 64), 0.0001), (4, 16, (256, 128, 64), 0.0005), (4, 16, (128, 64, 32), 0.0001), (4, 16, (128, 64, 32), 0.0005), (4, 16, (64, 32, 16), 0.0001), (4, 16, (64, 32, 16), 0.0005), (4, 32, (256, 128, 64), 0.0001), (4, 32, (256, 128, 64), 0.0005), (4, 32, (128, 64, 32), 0.0001), (4, 32, (128, 64, 32), 0.0005), (4, 32, (64, 32, 16), 0.0001), (4, 32, (64, 32, 16), 0.0005), (4, 64, (256, 128, 64), 0.0001), (4, 64, (256, 128, 64), 0.0005), (4, 64, (128, 64, 32), 0.0001), (4, 64, (128, 64, 32), 0.0005), (4, 64, (64, 32, 16), 0.0001), (4, 64, (64, 32, 16), 0.0005), (8, 16, (256, 128, 64), 0.0001), (8, 16, (256, 128, 64), 0.0005), (8, 16, (128, 64, 32), 0.0001), (8, 16, (128, 64, 32), 0.0005), (8, 16, (64, 32, 16), 0.0001), (8, 16, (64, 32, 16), 0.0005), (8, 32, (256, 128, 64), 0.0001), (8, 32, (256, 128, 64), 0.0005), (8, 32, (128, 64, 32), 0.0001), (8, 32, (128, 64, 32), 0.0005), (8, 32, (64, 32, 16), 0.0001), (8, 32, (64, 32, 16), 0.0005), (8, 64, (256, 128, 64), 0.0001), (8, 64, (256, 128, 64), 0.0005), (8, 64, (128, 64, 32), 0.0001), (8, 64, (128, 64, 32), 0.0005), (8, 64, (64, 32, 16), 0.0001), (8, 64, (64, 32, 16), 0.0005)]\n",
      "54\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "time_step = (1,4,8)  # the length of history (number of previous data instances) to include\n",
    "batch_size = (16,32,64) # the model performs a weight update for every batch, smaller batch means faster learning but les stable weights\n",
    "#a=((1,2),(3,4))\n",
    "#H1 = (256,128,64) # number of neurons in the bottom hidden layer\n",
    "#H2 = (128,64,32) # number of neurons in the middle hidden layer\n",
    "#H3 = (64,32,16) # number of neurons in the top hidden layer\n",
    "H_1_2_3=((256,128,64),(128,64,32),(64,32,16))\n",
    "dropout_W1 = (0.5,0) # drop out weight (for preventing over-fitting) in H1\n",
    "dropout_U1 = (0.5,0) # drop out weight (for preventing over-fitting) in H1\n",
    "dropout_W2 = (0) # drop out weight (for preventing over-fitting) in H2\n",
    "dropout_U2 = (0) # drop out weight (for preventing over-fitting) in H2\n",
    "dropout_W3 = (0) # drop out weight (for preventing over-fitting) in H3\n",
    "dropout_U3 = (0) # drop out weight (for preventing over-fitting) in H3\n",
    "lr=(0.0001,0.0005) # learning rate for the optimization algorithm \n",
    "#list(itertools.product(time_step,batch_size,H1,H2,H3,dropout_W1,dropout_U1,dropout_W2,dropout_U2,dropout_W3,dropout_U3,lr))\n",
    "Parameter_Grid=list(itertools.product(time_step,batch_size,H_1_2_3,lr))\n",
    "print(Parameter_Grid)\n",
    "print(len(Parameter_Grid))\n",
    "\n",
    "#[''.join(x) for x in itertools.product(t1, t2)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
