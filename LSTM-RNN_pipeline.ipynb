{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.4\n"
     ]
    }
   ],
   "source": [
    "# importing libraries \n",
    "import numpy as np\n",
    "from attention_utils import get_data # scirpt to genetate data\n",
    "import pandas as pd\n",
    "#from __future__ import print_function\n",
    "# import keras\n",
    "import keras\n",
    "#keras.__version__\n",
    "print(keras.__version__)\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "# all modules of keras for lSTM-RNNs\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "#from keras.layers import Merge # problem with Merge because I now use Keras 2.2.4. Merge is replaced by add\n",
    "from keras.layers import add\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import RMSprop,Adamax\n",
    "from keras import backend as K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading files\n",
    "# features\n",
    "X_test=pd.read_csv('Test_set_1L_AC_aud_feat_win5_lag1_gsr.csv', sep=',',header=None) # reading ok #X_test.values\n",
    "X_train=pd.read_csv('Train_set_1L_AC_aud_feat_win5_lag1_gsr.csv', sep=',',header=None)\n",
    "X_valid=pd.read_csv('Valid_set_1L_AC_aud_feat_win5_lag1_gsr.csv', sep=',',header=None)\n",
    "# labels\n",
    "Y_test=pd.read_csv('Test_set_synch_feat_win5_lag1_Awe.csv', sep=',',header=None)\n",
    "Y_train=pd.read_csv('Train_set_synch_feat_win5_lag1_Awe.csv', sep=',',header=None)\n",
    "Y_valid=pd.read_csv('Valid_set_synch_feat_win5_lag1_Awe.csv', sep=',',header=None)\n",
    "# small sets\n",
    "X_test_s=X_test[0:101]\n",
    "X_train_s=X_train[0:201]\n",
    "X_valid_s=X_valid[0:101]\n",
    "Y_test_s=Y_test[0:101]\n",
    "Y_train_s=Y_train[0:201]\n",
    "Y_valid_s=Y_valid[0:101]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1100\n",
      "19428\n"
     ]
    }
   ],
   "source": [
    "n_features = X_train.shape[1] # columns are features , rows are observations\n",
    "print(n_features)\n",
    "input_dim = n_features\n",
    "n_observation = X_train.shape[0] # columns are features , rows are observations\n",
    "print(n_observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define variables\n",
    "nb_features = n_features # total number of features, also the number of neurons in the input layer of LSTM\n",
    "\n",
    "time_step = 3  # the length of history (number of previous data instances) to include\n",
    "batch_size = 32 # the model performs a weight update for every batch, smaller batch means faster learning but les stable weights\n",
    "nb_epoch = 1000 # number of total epochs to train the model\n",
    "H1 = 128 # number of neurons in the bottom hidden layer\n",
    "H2 = 64 # number of neurons in the middle hidden layer\n",
    "H3 = 32 # number of neurons in the top hidden layer\n",
    "dropout_W1 = 0.5 # drop out weight (for preventing over-fitting) in H1\n",
    "dropout_U1 = 0.5 # drop out weight (for preventing over-fitting) in H1\n",
    "dropout_W2 = 0 # drop out weight (for preventing over-fitting) in H2\n",
    "dropout_U2 = 0 # drop out weight (for preventing over-fitting) in H2\n",
    "dropout_W3 = 0 # drop out weight (for preventing over-fitting) in H3\n",
    "dropout_U3 = 0 # drop out weight (for preventing over-fitting) in H3\n",
    "\n",
    "#opt_func = RMSprop(lr=0.0001) # training function\n",
    "opt_func = Adamax(lr=0.0005, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "\n",
    "# if the validation loss isn't decreasing for a number of epochs, stop training to prevent over-fitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to reshape the panda.DataFrame format data to Keras style: (batch_size, time_step, nb_features)\n",
    "def reshape_data(data, n_prev = time_step):\n",
    "    docX = []\n",
    "    for i in range(len(data)):\n",
    "        if i < (len(data)-n_prev):\n",
    "            docX.append(data.iloc[i:i+n_prev].as_matrix())\n",
    "        else: # the frames in the last window use the same context\n",
    "            docX.append(data.iloc[(len(data)-n_prev):len(data)].as_matrix())\n",
    "    alsX = np.array(docX)\n",
    "    return alsX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshaping the panda.DataFrame format data to Keras style: (batch_size, time_step, nb_features)\n",
    "# shape (nb_observations, nb_features)\n",
    "#X_Test = reshape_data(X_test)\n",
    "#X_Train = reshape_data(X_train)\n",
    "#X_Valid = reshape_data(X_valid)\n",
    "\n",
    "# small set\n",
    "X_Test = reshape_data(X_test_s)\n",
    "X_Train = reshape_data(X_train_s)\n",
    "X_Valid = reshape_data(X_valid_s)\n",
    "# after reshaping: shape (nb_observations,time_step,nb_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom evaluation metrics\n",
    "def pearson_cc(y_true, y_pred):\n",
    "    fsp = y_pred - K.mean(y_pred,axis=0)   \n",
    "    fst = y_true - K.mean(y_true,axis=0) \n",
    "    devP = K.std(y_pred,axis=0)  \n",
    "    devT = K.std(y_true,axis=0)\n",
    "\n",
    "    return K.sum(K.mean(fsp*fst,axis=0)/(devP*devT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turn off the warnings, be careful when use this\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model structure\n",
    "model = Sequential()\n",
    "model.add(LSTM(H1, input_shape=(time_step, nb_features),dropout_W=dropout_W1, dropout_U=dropout_U1, return_sequences=True)) \n",
    "# bottom hidden layer\n",
    "model.add(LSTM(H2, dropout_W=dropout_W2, dropout_U=dropout_U2, return_sequences=True)) # middle hidden layer\n",
    "model.add(LSTM(H3, dropout_W=dropout_W3, dropout_U=dropout_U3, return_sequences=False)) # top hidden layer\n",
    "model.add(Dense(1, activation='sigmoid')) # output layer, regression task, value range [-1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling\n",
    "model.compile(loss=pearson_cc, optimizer=opt_func, metrics=[pearson_cc,'mse']) \n",
    "# define the optimizer for training, use cc and mse as the evaluation metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb328ade80>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# carry out training\n",
    "model.fit(X_Train, Y_train_s, batch_size=batch_size, nb_epoch=nb_epoch, validation_data=(X_Valid, Y_valid_s), callbacks=[early_stopping], verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test cc: 0.19169994510046326\n",
      "Test mse: 0.009705001489480607\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluation\n",
    "test_score, test_cc, test_mse = model.evaluate(X_Test, Y_test_s, batch_size=batch_size, verbose=0)\n",
    "print('Test cc:', test_cc)\n",
    "print('Test mse:', test_mse)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output predictions\n",
    "test_pred = model.predict(X_Test)\n",
    "test_df = pd.DataFrame(test_pred)\n",
    "test_df.to_csv('prediction.csv', mode='a', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
